#!/usr/bin/env python
# -*- coding: utf-8 -*-
##############################################################################
#
#     This file is part of connector, an Odoo module.
#
#     Author: St√©phane Bidoul <stephane.bidoul@acsone.eu>
#     Copyright (c) 2015 ACSONE SA/NV (<http://acsone.eu>)
#
#     connector is free software: you can redistribute it and/or
#     modify it under the terms of the GNU Affero General Public License
#     as published by the Free Software Foundation, either version 3 of
#     the License, or (at your option) any later version.
#
#     connector is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU Affero General Public License for more details.
#
#     You should have received a copy of the
#     GNU Affero General Public License
#     along with connector.
#     If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################
"""
odoo-connector-runner

What's this?
============
This is an alternative to connector workers, with the goal
of resolving issues due to the polling nature of workers:
* jobs do not start immediately even if there is a free worker
* workers may starve while other workers have too many jobs enqueued

It is fully compatible with the connector mechanism and only
replaces workers.

How?
====
* This process receives postgres NOTIFY messages each time jobs change state.
* It does not run jobs itself, but asks Odoo to run them through an
  anonymous HTTP request [1].

How to use
==========
* adapt the _TMP_* variables below to suit your needs
* start Odoo with --workers > _TMP_MAX_RUNNING_JOBS
  and --load=web,connector
* disable "Enqueue Jobs" cron
* do NOT start openerp-connector-worker
* run python odoo-connector-runner (only dependency are psycopg2 and requests)
* create jobs (eg using base_import_async) and observe they
  start immediately and in parallel

TODO
====
* See in the code below.

Notes
=====
[1] From a security standpoint, it is safe to have an anonymous HTTP
    request because this request only accepts to run jobs that are
    enqueued.
"""

from contextlib import closing
import logging
import select
import threading
import time

import requests
import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT

from channels import ChannelManager, STATE_ENQUEUED, STATES_NOT_DONE

# TODO: This is currently working nicely but for only
#       one database. Also, the approach is relatively
#       brute force, as the queue_job is queried each
#       time a notification is received. So the next step
#       is to maintain a in-memory list of jobs to run
#       and use the information in the notifications to
#       decide what to run and when. Querying the database
#       will be done only at initialization and to re-sync
#       the state in case of bug or missed notifications.
#       This opens the path to a simple implementation of
#       job channels (https://github.com/OCA/connector/issues/43).

# TODO: since STATE_ENQUEUED is now very short lived state
#       we can automatically requeue (set pending) all
#       jobs that are enqueued since more than a few seconds
#       this is important as jobs will be stuck in that
#       state if this odoo-connector-runner runs while odoo does not

# TODO: should we try to recover from lost postgres connections?

# TODO: make all this configurable
_TMP_DATABASE = "jobrunner-1-v80"
_TMP_ODOO_URL = "http://localhost:8069"
_TMP_CONFIG = "root:4,root.sub:3"
_TMP_SELECT_TIMEOUT = 60


# TODO: configurable
logging.basicConfig(format='%(asctime)s %(name)s %(levelname)s:%(message)s',
                    level=logging.DEBUG)
_logger = logging.getLogger("odoo-connector-runner")


def _async_http_get(url):
    # TODO: better way to HTTP GET asynchronously (grequest, ...)?
    #       if this was python3 I would be doing this with
    #       asyncio, aiohttp and aiopg
    def urlopen():
        try:
            _logger.debug("GET %s", url)
            # we are not interested in the result, so we set a short timeout
            # but not too short so we log errors when Odoo is not running at all
            requests.get(url, timeout=1)
        except requests.Timeout:
            pass
        except:
            _logger.exception("exception in GET %s", url)
    thread = threading.Thread(target=urlopen)
    thread.daemon = True
    thread.start()


class OdooConnectorRunner:

    def __init__(self):
        self.channel_manager = ChannelManager()
        self.channel_manager.simple_configure(_TMP_CONFIG)
        self.conn = psycopg2.connect(database=_TMP_DATABASE)
        self.conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with closing(self.conn.cursor()) as cr:
            # this is the trigger that sends notifications when jobs change
            # TODO: perhaps we don't need to trigger ON DELETE?
            cr.execute("""
                DROP TRIGGER IF EXISTS queue_job_notify ON queue_job;

                CREATE OR REPLACE
                    FUNCTION queue_job_notify() RETURNS trigger AS $$
                DECLARE
                    uuid TEXT;
                BEGIN
                    IF TG_OP = 'DELETE' THEN
                        uuid = OLD.uuid;
                    ELSE
                        uuid = NEW.uuid;
                    END IF;
                    PERFORM pg_notify('connector', current_database() || ',' || uuid);
                    RETURN NULL;
                END;
                $$ LANGUAGE plpgsql;

                CREATE TRIGGER queue_job_notify
                    AFTER INSERT OR UPDATE OR DELETE
                    ON queue_job
                    FOR EACH ROW EXECUTE PROCEDURE queue_job_notify();
            """)
            cr.execute("LISTEN connector")
        self.notify_jobs()

    def notify_jobs(self):
        # TODO: remove all jobs for database, in case we are reconnecting
        _logger.debug("loading all jobs")
        with closing(self.conn.cursor()) as cr:
            # TODO: channel_name
            # TODO: sequence
            cr.execute("SELECT NULL, uuid, 0, date_created, priority, eta, state " \
                       "  FROM queue_job WHERE state in %s", (STATES_NOT_DONE,))
            for channel_name, uuid, seq, date_created, priority, eta, state in cr.fetchall():
                self.channel_manager.notify(channel_name, uuid,
                                            seq, date_created, priority, eta, state)
        _logger.debug("loaded all jobs")

    def notify_job(self, uuid):
        with closing(self.conn.cursor()) as cr:
            # TODO: channel_name
            # TODO: sequence
            cr.execute("SELECT NULL, uuid, 0, date_created, priority, eta, state " \
                       "  FROM queue_job WHERE uuid = %s", (uuid,))
            res = cr.fetchall()
            if res:
                for channel_name, uuid, seq, date_created, priority, eta, state in res:
                    self.channel_manager.notify(channel_name, uuid,
                                                seq, date_created, priority, eta, state)
            else:
                # job not found: remove it
                _logger.warning("job %s not found in database", uuid)
                self.channel_manager.notify(None, uuid,
                                            None, None, None, None, None)

    def run_jobs(self):
        with closing(self.conn.cursor()) as cr:
            for job in self.channel_manager.get_jobs_to_run():
                _logger.debug("asking Odoo to run job %s", job.uuid)
                cr.execute("UPDATE queue_job "
                           "   SET state=%s, "
                           "       date_enqueued=NOW() "
                           "WHERE uuid=%s",
                           (STATE_ENQUEUED, job.uuid))
                _async_http_get(_TMP_ODOO_URL +
                                "/runjob?db=%s&job_uuid=%s" %
                                (_TMP_DATABASE, job.uuid,))

    def process_notifications(self):
        while self.conn.notifies:
            notification = self.conn.notifies.pop()
            db, uuid = notification.payload.split(',')
            self.notify_job(uuid)

    def wait_notification(self):
        if self.conn.notifies:
            return
        # wait for something to happen in the queue_job table
        conns, _, _ = select.select([self.conn], [], [],
                                    _TMP_SELECT_TIMEOUT)
        if conns:
            for conn in conns:
                conn.poll()
        else:
            _logger.debug("select timeout")

    def run_forever(self):
        _logger.info("starting")
        while True:
            try:
                self.process_notifications()
                self.run_jobs()
                self.wait_notification()
            except KeyboardInterrupt:
                _logger.info("stopping")
                break
            except:
                _logger.exception("exception, sleeping a bit and continuing")
                time.sleep(1)


if __name__ == "__main__":
    OdooConnectorRunner().run_forever()
